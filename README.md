### Выполнил Глушин Никита Дмитриевич, М8О-406Б-21

## Лабораторная работа 6

| Модель                           | Accuracy | Precision | Recall | F1     |
|----------------------------------|----------|-----------|--------|--------|
| ResNet18 Базовый Baseline        | 1.0000   | 1.0000    | 1.0000 | 1.0000 |
| ResNet18 Улучшенный Baseline     | 0.9933   | 0.9737    | 1.0000 | 0.9867 |
| ViT_B_16 Базовый Baseline        | 0.9930   | 1.0000    | 0.9730 | 0.9860 |
| ViT_B_16 Улучшенный Baseline     | 0.8800   | 1.0000    | 0.5135 | 0.6786 |
| Simple CNN Базовый Baseline      | 0.9340   | 0.8000    | 0.9730 | 0.8780 |
| Simple CNN Улучшенный Baseline   | 0.8610   | 0.6380    | 1.0000 | 0.7790 |
| Simple ViT Базовый Baseline      | 0.9340   | 0.8140    | 0.9460 | 0.8750 |
| Simplte ViT Улучшенный Baseline  | 0.9470   | 0.8920    | 0.8920 | 0.8920 |

## Лабораторная работа 7

| Модель                                  | Loss   | IoU    |
|-----------------------------------------|--------|--------|
| Unet Базовый Baseline                   | 0.6000 | 0.2200 |
| Unet Улучшенный Baseline                | 1.2600 | 0.1500 |
| Segformer Базовый Baseline              | 0.4832 | 0.2774 |
| Segformer Улучшенный Baseline           | 0.5620 | 0.2328 |
| Simple Unet Базовый Baseline            | 1.0676 | 0.1254 |
| Simple Unet Улучшенный Baseline         | 1.0841 | 0.1241 |
| Simple Transformer Базовый Baseline     | 1.5499 | 0.0762 |
| Simple Transformer Улучшенный Baseline  | 1.1704 | 0.0952 |

## Лабораторная работа 8

| Модель                                      | mAP50  | mAP50-95 |
|---------------------------------------------|--------|-----------|
| YOLO Базовый Baseline                       | 0.7802 | 0.4786    |
| YOLO Улучшенный Baseline                    | 0.7787 | 0.4711    |
| Собственная реализация Базовый Baseline     | 0.2436 | 0.0833    |
| Собственная реализация Улучшенный Baseline  | 0.5570 | 0.2703    |

## Заключение

# Общий вывод

Анализ результатов трёх лабораторных работ показал, что для задач на основе данного датасета (классификация, сегментация и детекция объектов) встроенные архитектуры, такие как ResNet, Segformer и YOLO, демонстрируют наилучшие результаты по сравнению с самостоятельно реализованными моделями.

В задачах классификации (лаб. 6) наилучшие показатели показали модели ResNet и сверточные нейронные сети, тогда как попытки улучшить обучение с помощью аугментации данных не дали значимого прироста, что указывает на необходимость более длительного обучения и возможного увеличения объема данных. При этом собственные реализации показывают достойные результаты и близки по точности к предобученным моделям.

В задаче сегментации (лаб. 7) лучше всего себя проявила модель Segformer, немного опережая Unet по основным метрикам. Самописные архитектуры существенно уступали, справляясь в основном с крупными объектами. Это также указывает на нехватку обучающих данных и возможно — на недостаточное количество эпох обучения.

В задаче детекции объектов (лаб. 8) встроенная модель YOLO даже при ограниченных ресурсах показывает уверенные результаты. При улучшении бейзлайна удалось заметно увеличить метрику recall. Несмотря на то, что собственная реализация показала более слабые результаты, есть потенциал достижения уровня YOLO при более продолжительном и детальном обучении.

В целом, встроенные модели демонстрируют более высокую эффективность благодаря своей сложности и предобученности, но собственные реализации показывают адекватные результаты, что говорит о корректности построения архитектур. Улучшение качества всех моделей возможно при увеличении объема обучающей выборки и времени обучения.


